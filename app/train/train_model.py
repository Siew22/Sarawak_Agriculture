# train/train_model.py (ä¸ºä½ å®šåˆ¶çš„ã€6GBæœ€ç»ˆçº¯å‡€ç‰ˆ)
import os
from pathlib import Path
# --- å…³é”®ä¿®å¤ï¼šåœ¨æ‰€æœ‰å…¶ä»–å¯¼å…¥ä¹‹å‰ï¼Œä¸ºPyTorchæŒ‡å®šä¸€ä¸ªå®‰å…¨çš„ç¼“å­˜ç›®å½• ---
# è¿™ä¼šå‘Šè¯‰PyTorch/Torchvisionå°†æ‰€æœ‰ä¸‹è½½çš„æ¨¡å‹æƒé‡éƒ½å­˜æ”¾åœ¨é¡¹ç›®å†…éƒ¨ï¼Œ
# ä»è€Œå½»åº•é¿å…åœ¨ç”¨æˆ·ä¸»ç›®å½•ä¸‹çš„æƒé™é—®é¢˜ã€‚
torch_cache_dir = Path(__file__).resolve().parent.parent.parent / "temp" / "torch_cache"
os.makedirs(torch_cache_dir, exist_ok=True)
os.environ['TORCH_HOME'] = str(torch_cache_dir)
import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, models, transforms
from torch.utils.data import DataLoader, Dataset, ConcatDataset, random_split
import json
from tqdm import tqdm
import time
from PIL import Image

# --- 6GB VRAM è‡ªç ”é…ç½® (ä½¿ç”¨ä½ æŒ‡å®šçš„è·¯å¾„) ---
# --- â†“â†“â†“ ä½ æŒ‡å®šçš„ã€æœ€ç»ˆçš„æ•°æ®æºè·¯å¾„ï¼â†“â†“â†“ ---
DATA_DIRS = [
    '../../Mydataset/kaggle_black_pepper_dataset',
    '../../Mydataset/BLACK_PEPPER_DATASET',
]
# --- â†‘â†‘â†‘ è·¯å¾„é…ç½®ç»“æŸ â†‘â†‘â†‘ ---

MODEL_SAVE_PATH = '../../models_store/FINAL_PEPPER_MODEL_b0.pth'
LABELS_PATH = '../../models_store/final_pepper_labels.json'
BATCH_SIZE = 16 # 6GB VRAM çš„å®‰å…¨æ‰¹é‡å¤§å°
NUM_WORKERS = 2 # 6GB VRAM çš„å®‰å…¨CPUå·¥ä½œçº¿ç¨‹æ•°
NUM_EPOCHS = 80 # ä¿æŒè¶³å¤Ÿçš„è®­ç»ƒè½®æ¬¡
LEARNING_RATE = 0.001
MODEL_ARCHITECTURE = 'efficientnet_b2' # æ˜ç¡®ä½¿ç”¨è½»é‡çº§æ¨¡å‹


# --- CustomDatasetWrapper ä¿æŒä¸å˜ï¼Œç¡®ä¿å¤šè¿›ç¨‹å®‰å…¨ ---
class CustomDatasetWrapper(Dataset):
    def __init__(self, dataset, transform=None):
        self.dataset = dataset
        self.transform = transform
    def __len__(self): return len(self.dataset)
    def __getitem__(self, idx):
        try:
            image, label = self.dataset[idx]
            if self.transform: image = self.transform(image)
            return image, label
        except Exception as e:
            print(f"\nè­¦å‘Š: åŠ è½½ç´¢å¼• {idx} æ—¶å‡ºé”™: {e}. å°†å°è¯•åŠ è½½ä¸‹ä¸€ä¸ªæ ·æœ¬ã€‚")
            if len(self) == 0: return None, None
            return self.__getitem__((idx + 1) % len(self))

def train():
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    if device.type == 'cpu': 
        print("âš ï¸  è­¦å‘Š: æœªæ£€æµ‹åˆ°CUDA, è®­ç»ƒä¼šéå¸¸æ…¢ã€‚")
    else: 
        print(f"âœ… æ£€æµ‹åˆ°CUDAè®¾å¤‡: {torch.cuda.get_device_name(0)}")

    # 1. è‡ªåŠ¨ä»ä½ çš„ä¸¤ä¸ªæ–‡ä»¶å¤¹ä¸­æ•´åˆæ‰€æœ‰ç±»åˆ«
    print("æ­£åœ¨æ‰«ææŒ‡å®šçš„æ•°æ®æºå¹¶æ•´åˆç±»åˆ«...")
    all_class_names = set()
    for data_dir in DATA_DIRS:
        if os.path.isdir(data_dir):
            for class_name in os.listdir(data_dir):
                if os.path.isdir(os.path.join(data_dir, class_name)):
                    all_class_names.add(class_name)
        else:
            print(f"âš ï¸  è­¦å‘Š: æ•°æ®æºè·¯å¾„ '{data_dir}' ä¸å­˜åœ¨ï¼Œå·²è·³è¿‡ã€‚")
    
    sorted_class_names = sorted(list(all_class_names))
    if not sorted_class_names:
        print("âŒ é”™è¯¯ï¼šåœ¨æŒ‡å®šçš„æ•°æ®æºä¸­æ²¡æœ‰æ‰¾åˆ°ä»»ä½•ç±»åˆ«æ–‡ä»¶å¤¹ï¼")
        return
        
    NUM_CLASSES = len(sorted_class_names)
    idx_to_class = {str(i): name for i, name in enumerate(sorted_class_names)}
    
    os.makedirs(os.path.dirname(LABELS_PATH), exist_ok=True)
    with open(LABELS_PATH, 'w') as f: json.dump(idx_to_class, f, indent=4)
    print(f"âœ… æ ‡ç­¾æ–‡ä»¶å·²æ›´æ–°ï¼Œå…±æ‰¾åˆ° {NUM_CLASSES} ä¸ªå”¯ä¸€çš„èƒ¡æ¤’ç›¸å…³ç±»åˆ«ã€‚")
    print("å°†è¦è®­ç»ƒçš„ç±»åˆ«:", sorted_class_names)

    # 2. æ•°æ®å¢å¼º (é€‚é… B0 æ¨¡å‹çš„ 224x224 å°ºå¯¸)
    data_transforms = {
        'train': transforms.Compose([
            transforms.RandomResizedCrop(size=224, scale=(0.8, 1.0)),
            transforms.RandomHorizontalFlip(p=0.5),
            transforms.ColorJitter(brightness=0.2, contrast=0.2),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),
        ]),
        'val': transforms.Compose([
            transforms.Resize(256),
            transforms.CenterCrop(224),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),
        ]),
    }

    # 3. ç®€å•å¯é çš„æ•°æ®åŠ è½½é€»è¾‘
    print("\næ­£åœ¨ä»ä½ æŒ‡å®šçš„æ–‡ä»¶å¤¹åŠ è½½å¹¶åˆå¹¶æ•°æ®é›†...")
    all_datasets = []
    for data_dir in DATA_DIRS:
        if os.path.isdir(data_dir):
            try:
                dataset = datasets.ImageFolder(root=data_dir)
                all_datasets.append(dataset)
                print(f"  - âœ… å·²åŠ è½½æ•°æ®æº: '{data_dir}' (åŒ…å« {len(dataset)} å¼ å›¾ç‰‡)")
            except Exception as e:
                print(f"  - âŒ åŠ è½½ '{data_dir}' æ—¶å‡ºé”™: {e}")

    if not all_datasets:
        print("âŒ é”™è¯¯: æ²¡æœ‰åŠ è½½åˆ°ä»»ä½•æœ‰æ•ˆçš„è®­ç»ƒæ•°æ®ï¼")
        return
        
    full_dataset = ConcatDataset(all_datasets)
    print(f"\nâœ… æ•°æ®æ•´åˆå®Œæˆ: å…± {len(full_dataset)} å¼ å›¾ç‰‡ã€‚")

    # 4. è‡ªåŠ¨åˆ’åˆ†ä¸åŠ è½½
    print("æ­£åœ¨å°†æ€»æ•°æ®é›†åˆ’åˆ†ä¸ºè®­ç»ƒé›†å’ŒéªŒè¯é›† (80/20)...")
    train_size = int(0.8 * len(full_dataset))
    val_size = len(full_dataset) - train_size
    generator = torch.Generator().manual_seed(42)
    train_split, val_split = torch.utils.data.random_split(full_dataset, [train_size, val_size], generator=generator)
    
    train_dataset = CustomDatasetWrapper(train_split, data_transforms['train'])
    val_dataset = CustomDatasetWrapper(val_split, data_transforms['val'])
    
    dataloaders = {
        'train': DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True),
        'val': DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True),
    }
    print(f"âœ… æ•°æ®åŠ è½½å™¨å‡†å¤‡å°±ç»ª: è®­ç»ƒé›† {len(train_dataset)} å¼ , éªŒè¯é›† {len(val_dataset)} å¼ ã€‚")

    # 5. æ¨¡å‹å®šä¹‰ (100% è‡ªç ”, ä½¿ç”¨ B0)
    print(f"æ­£åœ¨æ„å»ºä¸€ä¸ªå…¨æ–°çš„ '{MODEL_ARCHITECTURE}' æ¨¡å‹ (100% å®Œå…¨è‡ªç ”)...")
    model = models.efficientnet_b2(weights='IMAGENET1K_V1') #num_classes=NUM_CLASSES)
    # 2. æ›¿æ¢æ‰æœ€åä¸€å±‚ï¼ˆåˆ†ç±»å™¨ï¼‰ï¼Œä»¥åŒ¹é…æˆ‘ä»¬è‡ªå·±çš„ç±»åˆ«æ•°é‡
    #    è¿™æ ·å¯ä»¥ä¿ç•™æ‰€æœ‰é¢„è®­ç»ƒå¥½çš„ç‰¹å¾æå–èƒ½åŠ›
    num_ftrs = model.classifier[1].in_features
    model.classifier[1] = nn.Linear(num_ftrs, NUM_CLASSES)

    model = model.to(device)

    # 6. ä¼˜åŒ–å™¨ä¸è®­ç»ƒå¾ªç¯
    criterion = nn.CrossEntropyLoss(label_smoothing=0.1)
    optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-2)
    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=NUM_EPOCHS)
    scaler = torch.cuda.amp.GradScaler(enabled=(device.type == 'cuda'))
    
    start_time = time.time()
    best_acc = 0.0

    print("\n--- å¼€å§‹â€œèƒ¡æ¤’ä¸“å®¶â€ä¼˜åŒ–è®­ç»ƒ (6GBç‰ˆ) ---")
    for epoch in range(NUM_EPOCHS):
        print(f'\nEpoch {epoch+1}/{NUM_EPOCHS} | å½“å‰å­¦ä¹ ç‡: {optimizer.param_groups[0]["lr"]:.6f}')
        print('-' * 25)
        for phase in ['train', 'val']:
            model.train() if phase == 'train' else model.eval()
            running_loss, running_corrects = 0.0, 0
            
            progress_bar = tqdm(dataloaders[phase], desc=f"{phase.capitalize()} Epoch {epoch+1}")
            for inputs, labels in progress_bar:
                if inputs is None: continue
                inputs, labels = inputs.to(device, non_blocking=True), labels.to(device, non_blocking=True)
                optimizer.zero_grad(set_to_none=True)
                with torch.set_grad_enabled(phase == 'train'):
                    with torch.cuda.amp.autocast(enabled=(device.type == 'cuda')):
                        outputs = model(inputs)
                        _, preds = torch.max(outputs, 1)
                        loss = criterion(outputs, labels)
                    if phase == 'train':
                        scaler.scale(loss).backward()
                        scaler.step(optimizer)
                        scaler.update()
                running_loss += loss.item() * inputs.size(0)
                running_corrects += torch.sum(preds == labels.data)
                progress_bar.set_postfix(loss=f'{loss.item():.4f}')

            if len(dataloaders[phase].dataset) > 0:
                epoch_loss = running_loss / len(dataloaders[phase].dataset)
                epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)
                print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')

                if phase == 'val' and epoch_acc > best_acc:
                    best_acc = epoch_acc
                    torch.save(model.state_dict(), MODEL_SAVE_PATH)
                    print(f"ğŸ‰ æ–°çš„æœ€ä½³è‡ªç ”ç»æµç‰ˆæ¨¡å‹å·²ä¿å­˜ (Accuracy: {best_acc:.4f}) ğŸ‰")
        
        scheduler.step()

    time_elapsed = time.time() - start_time
    print(f'\n--- è®­ç»ƒå®Œæˆ ---')
    print(f'æ€»è€—æ—¶: {time_elapsed // 60:.0f}åˆ† {time_elapsed % 60:.0f}ç§’')
    print(f'ğŸ† æœ€ä½³éªŒè¯é›†å‡†ç¡®ç‡: {best_acc:4f}')

if __name__ == "__main__":
    train()