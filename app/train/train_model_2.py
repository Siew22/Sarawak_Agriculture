import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import models, transforms
from torch.utils.data import DataLoader, Dataset, ConcatDataset, random_split
import os
import json
from tqdm import tqdm
import time
from PIL import Image

# --- 12GB VRAM è‡ªç ”æ——èˆ°é…ç½® ---
# --- â†“â†“â†“ ä½ æä¾›çš„ã€ç»å¯¹è¦æœ‰çš„è·¯å¾„åˆ—è¡¨ï¼â†“â†“â†“ ---
DATA_DIRS = [
    '../../PlantVillage-Dataset/raw/color', 
    '../../Mydataset/kaggle_black_pepper_dataset',
    '../../Mydataset/Pepper Diseases and Pests Detection/Pepper Diseases and Pests Detection/PepperDiseaseTest',
    '../../PlantVillage-Dataset/raw/grayscale',
    '../../PlantVillage-Dataset/raw/segmented',
    #'../../PlantVillage-Dataset/data_distribution_for_SVM/train',
    #'../../PlantVillage-Dataset/data_distribution_for_SVM/test',
    # æé†’ï¼šä»¥ä¸‹æ–‡ä»¶å¤¹é‡Œçš„å›¾ç‰‡æ˜¯æ··åœ¨ä¸€èµ·çš„ï¼Œå½“å‰è„šæœ¬ä¼šå¿½ç•¥å®ƒä»¬ï¼Œé™¤éä½ æ‰‹åŠ¨åˆ†ç±»
    # '../../Mydataset/Pepper Diseases and Pests Detection/...'
]
# --- â†‘â†‘â†‘ è·¯å¾„é…ç½®ç»“æŸ â†‘â†‘â†‘ ---

MODEL_SAVE_PATH = '../../models_store/PEPPER_ONLY_model_b2_FINAL.pth'
LABELS_PATH = '../../models_store/pepper_only_labels.json'
BATCH_SIZE = 32
NUM_WORKERS = 4
NUM_EPOCHS = 80
LEARNING_RATE = 0.001
MODEL_ARCHITECTURE = 'efficientnet_b2'


# --- â†“â†“â†“ å…³é”®ä¿®å¤ 1ï¼šå°†æ‰€æœ‰ç±»éƒ½å®šä¹‰åœ¨å‡½æ•°å¤–éƒ¨ï¼â†“â†“â†“ ---
class FinalPepperDataset(Dataset):
    """
    ä¸€ä¸ªç»ˆæçš„è‡ªå®šä¹‰æ•°æ®é›†ç±»ã€‚
    å®ƒç›´æ¥æ¥æ”¶ä¸€ä¸ªåŒ…å« (å›¾ç‰‡è·¯å¾„, æ ‡ç­¾ç´¢å¼•) çš„æ ·æœ¬åˆ—è¡¨æ¥å·¥ä½œã€‚
    """
    def __init__(self, samples, transform=None):
        self.samples = samples
        self.transform = transform

    def __len__(self):
        return len(self.samples)

    def __getitem__(self, idx):
        path, label = self.samples[idx]
        try:
            # ä½¿ç”¨ PIL åŠ è½½å›¾ç‰‡
            image = Image.open(path).convert('RGB')
            # åº”ç”¨æ•°æ®å¢å¼º
            if self.transform:
                image = self.transform(image)
            return image, label
        except Exception as e:
            print(f"\nè­¦å‘Š: åŠ è½½å›¾ç‰‡ {path} æ—¶å‡ºé”™: {e}. å°†å°è¯•åŠ è½½ä¸‹ä¸€ä¸ªæ ·æœ¬ã€‚")
            # å¦‚æœå½“å‰å›¾ç‰‡æŸåï¼Œåˆ™å®‰å…¨åœ°è·³è¿‡ï¼Œå¹¶åŠ è½½ä¸‹ä¸€ä¸ª
            if len(self) == 0: return None, None
            return self.__getitem__((idx + 1) % len(self))

def train():
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    if device.type == 'cpu': 
        print("âš ï¸  è­¦å‘Š: æœªæ£€æµ‹åˆ°CUDA, è®­ç»ƒä¼šéå¸¸æ…¢ã€‚")
    else: 
        print(f"âœ… æ£€æµ‹åˆ°CUDAè®¾å¤‡: {torch.cuda.get_device_name(0)}")

    # 1. â€œèƒ¡æ¤’ä¸“å±â€ç±»åˆ«æ‰«æ
    print("æ­£åœ¨æ‰«ææ‰€æœ‰æ•°æ®æºå¹¶æ™ºèƒ½ç­›é€‰'Pepper'ç›¸å…³ç±»åˆ«...")
    pepper_class_names = set()
    for data_dir in DATA_DIRS:
        if os.path.isdir(data_dir):
            for class_name in os.listdir(data_dir):
                if os.path.isdir(os.path.join(data_dir, class_name)) and 'pepper' in class_name.lower():
                    pepper_class_names.add(class_name)
    
    sorted_class_names = sorted(list(pepper_class_names))
    if not sorted_class_names:
        print("âŒ é”™è¯¯ï¼šåœ¨æ‰€æœ‰æ•°æ®æºä¸­ï¼Œæ²¡æœ‰æ‰¾åˆ°ä»»ä½•åŒ…å«'pepper'å­—çœ¼çš„ç±»åˆ«æ–‡ä»¶å¤¹ï¼")
        return
        
    NUM_CLASSES = len(sorted_class_names)
    class_to_idx = {name: i for i, name in enumerate(sorted_class_names)}
    idx_to_class = {str(i): name for i, name in enumerate(sorted_class_names)}
    
    os.makedirs(os.path.dirname(LABELS_PATH), exist_ok=True)
    with open(LABELS_PATH, 'w') as f: json.dump(idx_to_class, f, indent=4)
    print(f"âœ… æ ‡ç­¾æ–‡ä»¶å·²æ›´æ–°ï¼Œå…±æ‰¾åˆ° {NUM_CLASSES} ä¸ªä¸'Pepper'ç›¸å…³çš„å”¯ä¸€ç±»åˆ«ã€‚")
    print("å°†è¦è®­ç»ƒçš„ç±»åˆ«:", sorted_class_names)

    # 2. å›å½’ç¨³å®šå¯é çš„ torchvision.transforms
    data_transforms = {
        'train': transforms.Compose([
            transforms.RandomResizedCrop(size=260, scale=(0.7, 1.0)),
            transforms.RandomHorizontalFlip(p=0.5),
            transforms.RandomVerticalFlip(p=0.5),
            transforms.RandomRotation(degrees=90),
            transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.2, hue=0.1),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),
        ]),
        'val': transforms.Compose([
            transforms.Resize(288),
            transforms.CenterCrop(260),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),
        ]),
    }

    # --- 3. æœ€ç»ˆçš„ã€ç»å¯¹æ­£ç¡®çš„æ•°æ®åŠ è½½é€»è¾‘ (æ‰‹åŠ¨æ‰«æ) ---
    print("\næ­£åœ¨ä»å¤šä¸ªæ•°æ®æºä¸­åŠ è½½å¹¶åˆå¹¶'Pepper'ç›¸å…³çš„æ•°æ®é›†...")
    all_pepper_samples = [] # (å›¾ç‰‡è·¯å¾„, ç±»åˆ«å) çš„æ€»åˆ—è¡¨

    for data_dir in DATA_DIRS:
        if not os.path.isdir(data_dir):
            continue
        
        print(f"  - æ­£åœ¨æ‰«æ: {data_dir}")
        for class_name in os.listdir(data_dir):
            if class_name in pepper_class_names:
                class_path = os.path.join(data_dir, class_name)
                if os.path.isdir(class_path):
                    image_count = 0
                    for img_file in os.listdir(class_path):
                        if img_file.lower().endswith(('.png', '.jpg', '.jpeg')):
                            all_pepper_samples.append((os.path.join(class_path, img_file), class_name))
                            image_count += 1
                    if image_count > 0:
                        print(f"    - âœ… æ‰¾åˆ°äº† '{class_name}' ç±»åˆ«ï¼Œå¹¶æ·»åŠ äº† {image_count} å¼ å›¾ç‰‡ã€‚")
    
    if not all_pepper_samples:
        print("âŒ é”™è¯¯: åœ¨æ‰€æœ‰æ•°æ®æºä¸­ï¼Œæ²¡æœ‰æ‰¾åˆ°ä»»ä½•æœ‰æ•ˆçš„'Pepper'å›¾ç‰‡ï¼")
        return

    # å°†ç±»åˆ«åè½¬æ¢ä¸ºç±»åˆ«ç´¢å¼•
    final_samples = [(path, class_to_idx[label]) for path, label in all_pepper_samples]
    
    full_dataset = FinalPepperDataset(final_samples)
    print(f"\nâœ… æ•°æ®æ•´åˆå®Œæˆ: å…± {len(full_dataset)} å¼ 'Pepper'ç›¸å…³å›¾ç‰‡ã€‚")

    print("æ­£åœ¨å°†æ€»æ•°æ®é›†åˆ’åˆ†ä¸ºè®­ç»ƒé›†å’ŒéªŒè¯é›† (80/20)...")
    train_size = int(0.8 * len(full_dataset))
    val_size = len(full_dataset) - train_size
    generator = torch.Generator().manual_seed(42)
    train_split, val_split = torch.utils.data.random_split(full_dataset, [train_size, val_size], generator=generator)
    
    # ä¸ºåˆ’åˆ†åçš„å­é›†åº”ç”¨ä¸åŒçš„transform
    train_split.dataset.transform = data_transforms['train']
    val_split.dataset.transform = data_transforms['val']
    
    dataloaders = {
        'train': DataLoader(train_split, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True),
        'val': DataLoader(val_split, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True),
    }
    print(f"âœ… æ•°æ®åŠ è½½å™¨å‡†å¤‡å°±ç»ª: è®­ç»ƒé›† {len(train_split)} å¼ , éªŒè¯é›† {len(val_split)} å¼ ã€‚")

    print(f"æ­£åœ¨æ„å»ºä¸€ä¸ªå…¨æ–°çš„ '{MODEL_ARCHITECTURE}' æ¨¡å‹ (100% å®Œå…¨è‡ªç ”)...")
    model = models.efficientnet_b2(weights=None, num_classes=NUM_CLASSES)
    model = model.to(device)

    criterion = nn.CrossEntropyLoss(label_smoothing=0.1)
    optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-2)
    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=NUM_EPOCHS - 5, eta_min=1e-6)
    
    scaler = torch.cuda.amp.GradScaler(enabled=(device.type == 'cuda'))
    start_time = time.time()
    best_acc = 0.0

    print("\n--- å¼€å§‹â€œèƒ¡æ¤’ä¸“å±â€æ——èˆ°è®­ç»ƒ ---")
    for epoch in range(NUM_EPOCHS):
        print(f'\nEpoch {epoch+1}/{NUM_EPOCHS} | å½“å‰å­¦ä¹ ç‡: {optimizer.param_groups[0]["lr"]:.6f}')
        print('-' * 25)
        for phase in ['train', 'val']:
            model.train() if phase == 'train' else model.eval()
            running_loss, running_corrects = 0.0, 0
            
            progress_bar = tqdm(dataloaders[phase], desc=f"{phase.capitalize()} Epoch {epoch+1}")
            for inputs, labels in progress_bar:
                if inputs is None: continue
                inputs, labels = inputs.to(device, non_blocking=True), labels.to(device, non_blocking=True)
                optimizer.zero_grad(set_to_none=True)
                with torch.set_grad_enabled(phase == 'train'):
                    with torch.cuda.amp.autocast(enabled=(device.type == 'cuda')):
                        outputs = model(inputs)
                        _, preds = torch.max(outputs, 1)
                        loss = criterion(outputs, labels)
                    if phase == 'train':
                        scaler.scale(loss).backward()
                        scaler.step(optimizer)
                        scaler.update()
                running_loss += loss.item() * inputs.size(0)
                running_corrects += torch.sum(preds == labels.data)
                progress_bar.set_postfix(loss=f'{loss.item():.4f}')

            # ç¡®ä¿æ•°æ®é›†éç©ºå†è®¡ç®—losså’Œacc
            if len(dataloaders[phase].dataset) > 0:
                epoch_loss = running_loss / len(dataloaders[phase].dataset)
                epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)
                print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')

                if phase == 'val' and epoch_acc > best_acc:
                    best_acc = epoch_acc
                    torch.save(model.state_dict(), MODEL_SAVE_PATH)
                    print(f"ğŸ‰ æ–°çš„æœ€ä½³èƒ¡æ¤’ä¸“å±æ¨¡å‹å·²ä¿å­˜ (Accuracy: {best_acc:.4f}) ğŸ‰")
        
        scheduler.step()

    time_elapsed = time.time() - start_time
    print(f'\n--- è®­ç»ƒå®Œæˆ ---')
    print(f'æ€»è€—æ—¶: {time_elapsed // 60:.0f}åˆ† {time_elapsed % 60:.0f}ç§’')
    print(f'ğŸ† æœ€ä½³éªŒè¯é›†å‡†ç¡®ç‡: {best_acc:4f}')

if __name__ == "__main__":
    train()